 
Senior DevOps Engineer – Master Interview Q&A Guide
 
AWS
Q1: How would you design a highly available, fault-tolerant architecture for a web application in AWS?
Answer:
Use multiple Availability Zones with an Application Load Balancer distributing traffic to an Auto Scaling Group of EC2 instances (or ECS/EKS services). Place static assets in S3 and serve via CloudFront for global caching. Use RDS Multi-AZ or Aurora for database redundancy. Enable Route 53 health checks and DNS failover. Apply IAM least privilege, encrypt data in transit (TLS) and at rest (KMS), and monitor with CloudWatch and CloudTrail.
 
Q2: Difference between ALB, NLB, and CLB, and when to use each?
Answer:
•	ALB (Application Load Balancer): Layer 7, supports path/host-based routing, good for HTTP/HTTPS and microservices.
•	NLB (Network Load Balancer): Layer 4, very low latency, handles millions of requests/sec, best for TCP/UDP and high-performance workloads.
•	CLB (Classic Load Balancer): Legacy option supporting L4 and L7, fewer features, generally used only for older systems.
 
Q3: AWS IAM best practices?
Answer:
Apply least privilege to all IAM entities. Prefer IAM roles over access keys. Rotate keys regularly and remove unused credentials. Enable MFA for all users. Use Service Control Policies (SCPs) in AWS Organizations. Monitor access with CloudTrail and use IAM Access Analyzer to detect overly permissive policies.
 
Q4: Cost optimization in AWS?
Answer:
Right-size resources based on CloudWatch metrics. Purchase Reserved Instances or Savings Plans for predictable workloads. Use Spot Instances for fault-tolerant jobs. Enable S3 lifecycle policies to move infrequently accessed data to cheaper tiers. Turn off unused resources. Use Cost Explorer and Budgets to track and alert on spending.
 
Q5: What’s the difference between a Security Group and a Network ACL?
Answer:
•	Security Group: Stateful, operates at the instance level. Return traffic is automatically allowed. Rules are evaluated as a whole.
•	Network ACL: Stateless, operates at the subnet level. Return traffic must be explicitly allowed. Rules are evaluated in numerical order.
Typically, Security Groups are used for primary access control, NACLs as an additional layer of defense.
 
Q6: How would you design a secure VPC for a multi-tier application?
Answer:
Use public subnets for load balancers and bastion hosts. Use private subnets for application and database servers. NAT Gateways in public subnets allow private subnets outbound internet access. Configure separate route tables for public and private subnets. Apply Security Groups for instance-level protection and NACLs for subnet-level control. Enable VPC Flow Logs for monitoring.
 
Q7: What’s the difference between an Internet Gateway, NAT Gateway, and VPC Endpoint?
Answer:
•	Internet Gateway (IGW): Allows internet access for resources in public subnets.
•	NAT Gateway: Allows private subnet resources to access the internet without exposing them to inbound traffic.
•	VPC Endpoint: Provides private connectivity to AWS services without traversing the public internet (Gateway type for S3/DynamoDB, Interface type for other services).
 
Q8: How do you handle cross-region or cross-account access in AWS?
Answer:
•	Cross-account: Use IAM role trust policies with sts:AssumeRole for temporary credentials.
•	Cross-region: Replicate resources using services like S3 Cross-Region Replication, RDS Read Replicas, or DynamoDB Global Tables. Use Route 53 latency-based routing for directing user traffic.
 
Q9: How would you implement disaster recovery for an AWS workload?
Answer:
Choose based on RPO/RTO:
•	Backup & Restore: Store backups in S3/Glacier; restore when needed.
•	Pilot Light: Keep minimal standby resources, scale up on failover.
•	Warm Standby: Keep smaller fully functional environment running.
•	Multi-Site Active-Active: Fully functional environments in multiple regions, with active traffic routing.
 
Q10: How do you troubleshoot high latency in an AWS application?
Answer:
Check CloudWatch metrics for CPU/memory/disk usage. Review ALB/NLB target response times. Analyze VPC Flow Logs for network issues. Use AWS X-Ray for request tracing. Verify that Auto Scaling is keeping up with demand and check for slow database queries or throttled resources.
 
Q11: How would you migrate an on-premises application to AWS with minimal downtime?
Answer:
Use AWS Database Migration Service for continuous replication. Sync static content using AWS DataSync or aws s3 sync. Set up the new environment in parallel, test thoroughly, then perform DNS cutover with Route 53. Use blue-green deployment to switch traffic seamlessly.
 
Q12: Explain AWS Auto Scaling strategies.
Answer:
•	Dynamic Scaling: Reacts to metrics like CPU utilization.
•	Scheduled Scaling: Adjusts capacity at known peak/off-peak times.
•	Predictive Scaling: Uses historical data and machine learning to forecast demand.
 
Q13: What’s the difference between ECS, EKS, and Fargate?
Answer:
•	ECS: AWS-managed container orchestration platform.
•	EKS: AWS-managed Kubernetes service.
•	Fargate: Serverless compute engine for ECS/EKS that removes the need to manage EC2 instances.
 
Q14: How do you ensure compliance (e.g., HIPAA, PCI) in AWS?
Answer:
Enable encryption at rest (KMS) and in transit (TLS). Use CloudTrail and Config for audit trails. Restrict network access using Security Groups and NACLs. Apply service-specific compliance settings (e.g., RDS encryption, S3 bucket policies). Obtain compliance documents from AWS Artifact.
 
Q15: How would you monitor and alert on AWS infrastructure health?
Answer:
Use CloudWatch metrics and alarms for system and application performance. Stream logs to CloudWatch Logs or ELK stack. Integrate alerts with SNS, Slack, or PagerDuty. Enable the AWS Health Dashboard for service notifications. Use third-party monitoring tools like Datadog or Prometheus for more detailed metrics.
 
Terraform
Q1: What is the difference between terraform plan and terraform apply?
Answer:
terraform plan previews the changes Terraform will make to reach the desired state without actually applying them. It shows what resources will be created, modified, or destroyed. terraform apply executes those changes and updates the infrastructure to match the configuration and state.
 
Q2: How do you manage Terraform state for multiple team members?
Answer:
Use remote state backends like AWS S3 with DynamoDB for state locking and consistency. This prevents concurrent modifications. Alternatively, use Terraform Cloud or Terraform Enterprise, which offer built-in state management, locking, and versioning. Avoid local state files in shared environments.
 
Q3: When should you use locals, data, and modules in Terraform?
Answer:
•	locals: For defining reusable values or expressions within a module or configuration to avoid repetition.
•	data: To fetch information about existing resources not managed by Terraform (e.g., AWS AMIs).
•	modules: To encapsulate and reuse complex resource definitions, enabling modular and maintainable infrastructure code.
 
Q4: How do you handle unexpected resource destruction or recreation in Terraform?
Answer:
Review the terraform plan output carefully to identify what’s causing the replacement. Check for changes in resource attributes marked as forcing recreation. Use lifecycle blocks with prevent_destroy or ignore_changes to protect critical resources. Ensure state file is consistent and investigate drift between state and real infrastructure.
 
Q5: How do you structure Terraform for multiple environments?
Answer:
Use separate workspaces or directories for each environment (dev, staging, prod). Share common code through modules. Pass environment-specific variables via terraform.tfvars files or environment variables. Ensure each environment has its own isolated state backend to prevent overlap.
 
Ansible
Q1: What is the difference between an Ansible role and a playbook?
Answer:
A playbook is a YAML file that defines tasks and the order of execution on hosts. A role is a reusable, structured collection of tasks, variables, files, and templates designed to encapsulate a specific functionality or component, making playbooks cleaner and more modular.
 
Q2: What does idempotency mean in Ansible, and why is it important?
Answer:
Idempotency means running the same Ansible playbook multiple times results in the same system state without making unnecessary changes. It is important because it ensures predictable and safe configuration management, minimizing disruptions.
 
Q3: How do you secure sensitive variables in Ansible?
Answer:
Use Ansible Vault to encrypt sensitive data like passwords and keys. Encrypt vault files before committing to source control. Alternatively, integrate with external secret managers like HashiCorp Vault or AWS Secrets Manager and retrieve secrets at runtime.
 
Q4: How do you handle partial failures during Ansible runs?
Answer:
Use --limit to rerun playbooks on failed hosts only. Use serial execution in playbooks to limit the number of hosts affected at once, reducing blast radius. You can also use error handling modules (block/rescue/always) to control task behavior on failures.
 
Q5: How do you debug a hung Ansible task?
Answer:
Increase verbosity with -vvv to get detailed logs. Check SSH connectivity and credentials. Use timeout settings. Try running the underlying command or module manually on the host to isolate issues. Use async and poll parameters for long-running tasks.
 
CI/CD
Q1: What is the difference between Continuous Integration, Continuous Delivery, and Continuous Deployment?
Answer:
•	Continuous Integration (CI): Developers frequently merge code changes to a shared repo; automated tests run on each merge to detect issues early.
•	Continuous Delivery (CD): Automatically prepares builds for release, typically deploying to staging environments, but requires manual approval for production.
•	Continuous Deployment: Extends CD by automatically deploying every successful build to production without manual intervention.
 
Q2: How would you implement a CI/CD pipeline for deploying to ECS or EKS?
Answer:
For ECS: Build Docker image → push to ECR → update ECS task definition → deploy with new task definition → run integration tests → promote or rollback.
For EKS: Build Docker image → push to registry → update Kubernetes manifests or Helm charts → apply to cluster → run tests → promote or rollback. Use tools like Jenkins, GitHub Actions, or CodePipeline to orchestrate steps.
 
Q3: How do you implement rollback in a CI/CD pipeline?
Answer:
Store and version deployable artifacts. On failure or manual trigger, redeploy the last known good artifact or manifest. Use deployment strategies like blue-green or canary deployments to simplify rollback by switching traffic back to the previous environment or version.
 
Q4: How do you optimize a slow CI/CD pipeline?
Answer:
Use parallel builds and tests where possible. Cache dependencies and Docker layers. Skip unnecessary steps for certain commits (e.g., documentation-only changes). Use incremental builds and avoid rebuilding everything from scratch. Consider distributed runners or build agents for scale.
 
Q5: Explain blue-green deployment and how it can be implemented in CI/CD.
Answer:
Blue-green deployment involves running two identical production environments (blue and green). One serves live traffic while the other runs the new version. After successful testing, traffic is switched to the new environment, minimizing downtime and enabling quick rollback by switching back. Implement with load balancers or service meshes in CI/CD workflows.
 
Scripting
Q1: How do you handle error handling in Bash scripts?
Answer:
Use set -e to exit on any error. Check command exit status via $? after critical commands. Use trap to clean up resources or handle signals gracefully. Use conditional statements to handle expected failures or retries.
 
Q2: What is the difference between set -e and manually checking error codes?
Answer:
set -e causes the script to exit immediately on any command failure, simplifying error handling but sometimes exiting unexpectedly. Manual checking (if statements with $?) allows granular control, such as custom error messages or recovery steps.
 
Q3: How would you list all files larger than 100MB in a directory and sort them by size?
Answer:
find . -type f -size +100M -exec ls -lh {} + | sort -k5 -rh
This command finds files over 100MB, lists them with human-readable sizes, then sorts them in reverse order by size.
 
Q4: How would you parse large JSON files efficiently without loading the entire file into memory?
Answer:
Use a streaming JSON parser such as Python’s ijson library, which iterates over JSON items one by one, avoiding loading the entire file at once. Example:
import ijson
with open('data.json', 'rb') as f:
    for item in ijson.items(f, 'item'):
        print(item)
 
Kubernetes
Q1: What are the differences between Deployment, StatefulSet, and DaemonSet?
Answer:
•	Deployment: Manages stateless pods with replicas; supports rolling updates and scaling.
•	StatefulSet: Manages stateful pods with stable network IDs and persistent storage; ordered deployment and scaling.
•	DaemonSet: Ensures a copy of a pod runs on each (or selected) node, useful for logging or monitoring agents.
 
Q2: How do you securely manage secrets in Kubernetes?
Answer:
Use Kubernetes Secrets for storing sensitive data. Enable encryption of Secrets at rest in etcd. Integrate with external secret stores like HashiCorp Vault or AWS Secrets Manager for dynamic secret injection. Avoid storing secrets in plaintext manifests or container images.
 
Q3: Explain Kubernetes networking basics.
Answer:
Each pod gets a unique IP within a flat network namespace. Pods communicate directly without NAT. The Container Network Interface (CNI) plugin manages pod networking. Services provide stable IP and DNS names, abstracting pod IPs and enabling load balancing within the cluster.
 
Q4: How do you achieve zero downtime deployments in Kubernetes?
Answer:
Use rolling updates in Deployments, ensuring new pods pass readiness probes before terminating old pods. Set maxUnavailable to 0 to avoid downtime. Optionally use canary deployments with partial traffic shifting.
 
Q5: How do you troubleshoot a pod stuck in CrashLoopBackOff?
Answer:
Check pod logs with kubectl logs. Inspect pod events with kubectl describe pod. Verify resource limits and environment variables. Debug interactively by running a shell inside the container or replicating the container command locally.
 
Q6: How do you handle persistent storage in Kubernetes?
Answer:
Use Persistent Volumes (PV) and Persistent Volume Claims (PVC) for storage abstraction. Configure StorageClasses for dynamic provisioning. Use StatefulSets for pods requiring stable storage and network identities.
 
Q7: What is the difference between Horizontal Pod Autoscaler (HPA) and Vertical Pod Autoscaler (VPA)?
Answer:
•	HPA: Scales the number of pod replicas based on CPU/memory or custom metrics.
•	VPA: Adjusts CPU/memory requests and limits for existing pods to optimize resource usage.
 
Q8: How do you implement RBAC in Kubernetes?
Answer:
Define Roles and ClusterRoles with permissions. Bind them to users or service accounts via RoleBindings or ClusterRoleBindings. Follow least privilege principle to restrict access as needed.
 
Q9: A service is not accessible externally. How do you debug this?
Answer:
Check the Service type (NodePort, LoadBalancer, Ingress). Verify pod endpoints are healthy. Check firewall/security group rules. Inspect Ingress controller configuration if used. Use kubectl port-forward as a temporary workaround.
 
Q10: What is the role of etcd in Kubernetes?
Answer:
etcd stores the cluster’s entire state and configuration data. It is critical for Kubernetes operation. Ensuring its high availability and regular backups is essential for cluster reliability and disaster recovery.
 
Q11: How do you upgrade a Kubernetes cluster with minimal downtime?
Answer:
Upgrade control plane nodes first. Drain and cordon worker nodes one at a time before upgrading them. Use rolling updates and verify workloads after each step. Maintain version compatibility between control plane and nodes during upgrade.
 
Q12: How would you monitor Kubernetes effectively?
Answer:
Deploy Prometheus for metrics collection and Grafana for dashboards. Use ELK/Fluentd or Loki for centralized logging. Implement OpenTelemetry for distributed tracing. Set alerts on key metrics and pod health.
 

Perfect — if you want to really separate senior-level Terraform engineers from mid-levels, you need questions that go beyond "what does a module do?" and dig into design patterns, collaboration, scaling, and pitfalls.
Here are some advanced Terraform interview questions with context and strong answers:
 
🔹 1. How do you manage Terraform state in a team environment? What problems can arise, and how do you solve them?
Answer:
•	Use a remote backend like S3 + DynamoDB (AWS) or Terraform Cloud/Enterprise for state storage and locking.
•	Problems that arise:
o	Race conditions (multiple people apply at once) → solved by state locking.
o	State drift (manual infra changes) → use terraform plan regularly, enforce IaC-only changes.
o	State corruption or loss → mitigate with versioned S3 buckets or Terraform Cloud automatic snapshots.
•	In very large environments, split state into workspaces or multiple state files (per env/service) to keep blast radius small.
 
🔹 2. What are some strategies for structuring Terraform code at scale?
Answer:
•	Modules: Abstract reusable patterns (e.g., VPC module, ECS service module).
•	Root modules per environment: e.g., prod/, staging/, dev/ directories with environment-specific variables.
•	DRY but not over-engineered: Share modules, but keep per-env root modules flexible.
•	Terragrunt or wrapper tooling: Helps enforce DRY, manage remote state, inject common variables.
•	Workspaces: Sometimes useful, but often avoided for prod vs non-prod separation to reduce risks.
 
🔹 3. Explain the difference between count and for_each. When would you use one vs the other?
Answer:
•	count: Index-based, creates N identical resources. Easy but fragile if resources are deleted/added in the middle (indexes shift).
•	for_each: Map/set-based, creates resources keyed by name. Safer for managing resources with stable identifiers.
•	Example:
o	Spinning up N EC2 instances? → count.
o	Creating IAM users from a list of names? → for_each.
 
🔹 4. How do you manage secrets in Terraform?
Answer:
•	Never hardcode secrets in .tf or .tfvars.
•	Use external secret stores: AWS SSM Parameter Store, AWS Secrets Manager, Vault.
•	Reference secrets dynamically (data "aws_secretsmanager_secret_version" { ... }).
•	Use environment variables + TF_VAR_ prefix for sensitive vars.
•	Enable sensitive = true in outputs to avoid logging secrets.
 
🔹 5. How would you handle a situation where a Terraform apply would destroy and recreate a critical resource (like an RDS DB) when you only want an in-place update?
Answer:
•	Investigate why (schema drift, immutable field changed).
•	Use lifecycle { prevent_destroy = true } on critical resources.
•	Plan strategy:
o	If possible, modify only updatable attributes.
o	If unavoidable, use blue/green migration: create new resource, sync data, cut over.
•	Peer review required for DB changes, sometimes separate pipelines for critical infra.
 
🔹 6. How do you test and validate Terraform code before applying in production?
Answer:
•	terraform validate + terraform fmt for syntax/style.
•	terraform plan in CI/CD with manual approval before apply.
•	Use policy-as-code (Sentinel, OPA) to enforce guardrails.
•	Unit-test modules with terraform-compliance or terratest (Go-based infra testing).
•	Apply in sandbox/staging before production.
 
🔹 7. How do you handle Terraform provider or module version upgrades safely?
Answer:
•	Pin provider/module versions in code (version = "~> 5.0").
•	Use terraform init -upgrade in a controlled environment.
•	Run terraform plan to see breaking changes.
•	Upgrade incrementally (avoid major jumps).
•	Test in non-prod first.
•	Keep a changelog of provider changes in the repo.
 
🔹 8. What is terraform import, and when would you use it?
Answer:
•	terraform import brings existing resources into Terraform state without re-creating them.
•	Use cases:
o	Migrating from manual infra → IaC.
o	Adding a resource created outside Terraform (e.g., via console).
•	Caveats: You still need to write the Terraform config for the resource manually — import only maps state, not code.
 
🔹 9. Have you dealt with Terraform state drift? How do you detect and resolve it?
Answer:
•	Detection: Run terraform plan often. CI/CD can run daily drift detection jobs.
•	Resolution:
o	If drift is acceptable → run terraform refresh or import changes.
o	If drift is unexpected → enforce IaC as source of truth and remove manual changes.
o	In regulated environments → disallow manual changes with IAM policies.
 
🔹 10. How do you design a multi-region or multi-account AWS setup with Terraform?
Answer:
•	Use multiple providers with aliases:
•	provider "aws" {
•	  alias  = "us_east"
•	  region = "us-east-1"
•	}
•	
•	provider "aws" {
•	  alias  = "us_west"
•	  region = "us-west-2"
•	}
•	Organize infrastructure by account/environment:
o	Shared services account (VPC, networking).
o	Application account(s).
o	Security/logging account.
•	Manage with separate state files per account/region to reduce blast radius.
•	Use automation (Terragrunt, pipelines) to apply consistently.
 
👉 These are the kind of experience-driven questions that force candidates to show whether they’ve just "used Terraform" vs actually designed and scaled Terraform at enterprise level.
Would you like me to also draft a Terraform “challenge exercise” you could give candidates (like a real-world problem to solve in 30–60 minutes)? That really helps filter seniors.

